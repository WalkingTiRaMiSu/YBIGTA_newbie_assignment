1. Direct Prompting, CoT Prompting, My Prompting을
0 shot, 3 shot, 5 shot 정답률을 표로 보여주세요!

|shot|Direct|CoT|My|
|:----:|:------:|:---:|:---:|
|0|0.26|0.58|0.7|
|3|0.2|0.62|0.75|
|5|0.18|0.68|0.74|

2. CoT Prompting이 Direct Prompting에 비해
왜 좋을 수 있는지에 대해서 서술해주세요!  
Direct prompting은 문제의 답만을 예시로 제공하며 이를 모방하는 형식입니다. 그러나 결과만을 따라하기 때문에 문제 해결 과정이 존재하지 않습니다. 이와 다르게 Cot Prompting은 모델에 사고 흐름을 제시해주며 더 논리적인 답을 생성할 수 있게 해줍니다. 따라서 수학과 같은 논리적 흐름이 중요한 문제에서 CoT Prompting이 Direct Prompting에 비해 좋을 수 있었습니다.


3. 본인이 작성한 프롬프트 기법이 CoT에 비해서
왜 더 좋을 수 있는지에 대해서 설명해주세요!  
제가 작성한 프롬포트 또한 CoT처럼 사고 흐름을 제시해줍니다. 그러나 여기에 그치지 않고 세계적인 수학 대회 코치라는 역할을 부여함으로써 더욱 엄격하고 신중한 추론을 유도했습니다. 추가로 답 제출 전에 검토 과정을 거치게 하여 논리적 오류를 범하지 않게 하였습니다. 즉, CoT의 장점을 기반으로 하며 동시에 논리적 검토와 형식 등을 추가함으로써 모델이 더욱 명확하고 책임감있게 답을 도출하게 되고 결과적으로 CoT보다 높은 정확도를 보여주게 됩니다.

**성능을 올리기 위해 시도한 프롬포트**
1. 올림피아드와 같은 수학 대회에 나간 상황 가정  
   역할을 부여한 것처럼, 상황을 가정하면 모델의 정확도가 더욱 높아지지 않을까 라고 생각
   --> 그러나 큰 상승을 노리지 못하였고 오히려 더 낮아지게 됨. 프롬포트가 오히려 무거워진 게 아닐까 생각.
2. 한 문제를 틀렸을 경우 패널티 부여 상황 가정
   한 줄로만 썼을 경우와 여러 줄에 걸쳐 썼을 때, 정확도가 크게 달랐음.
   --> 여러 줄에 걸쳐 쓴 경우 과한 압박으로 모델의 혼란 유도 -> 큰 정확도 향상이 이루어지지 않음.
3. 형식을 좀 더 자세하게 요청했을 때
   --> 형식을 더욱 제한하면 성능이 오르지 않을까 했지만 간결하고 명확하게 요청한 경우가 더 효과적임.

*결론*  
**프롬포트를 더 길고 자세하게 요청하면 성능이 오를 것이라고 기대하였으나 결과는 아니었습니다. LLM에게는 장황한 프롬포트보다 오히려 적당히 간결하고 명확한 프롬포트가 성능을 올리는 데에 큰 효과가 있다는 것을 알았습니다.**
   
